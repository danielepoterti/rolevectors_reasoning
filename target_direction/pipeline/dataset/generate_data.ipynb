{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Target Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>role cate</th>\n",
       "      <th>occupation cate</th>\n",
       "      <th>merged_cate</th>\n",
       "      <th>N-gram Frequency (2018-2019)</th>\n",
       "      <th>mmlu</th>\n",
       "      <th>interpersonal</th>\n",
       "      <th>gender</th>\n",
       "      <th>align_words</th>\n",
       "      <th>gender_role_cate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>work</td>\n",
       "      <td>psychology</td>\n",
       "      <td>psychology</td>\n",
       "      <td>4.646573e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politician</td>\n",
       "      <td>work</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>5.218259e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sheriff</td>\n",
       "      <td>work</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>7.653504e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>governer</td>\n",
       "      <td>work</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>3.078719e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>geneticist</td>\n",
       "      <td>work</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>2.580220e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>biologist</td>\n",
       "      <td>work</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>1.110472e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>physicist</td>\n",
       "      <td>work</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>2.030176e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>teacher</td>\n",
       "      <td>school</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>5.522994e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chemist</td>\n",
       "      <td>work</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>1.986987e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ecologist</td>\n",
       "      <td>work</td>\n",
       "      <td>natural science</td>\n",
       "      <td>natural science</td>\n",
       "      <td>2.505230e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nurse</td>\n",
       "      <td>work</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "      <td>2.494348e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>doctor</td>\n",
       "      <td>work</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "      <td>5.117561e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>physician</td>\n",
       "      <td>work</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "      <td>1.669908e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dentist</td>\n",
       "      <td>work</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "      <td>2.256031e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>work</td>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "      <td>9.010343e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>work</td>\n",
       "      <td>math</td>\n",
       "      <td>math</td>\n",
       "      <td>6.469216e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mathematician</td>\n",
       "      <td>work</td>\n",
       "      <td>math</td>\n",
       "      <td>math</td>\n",
       "      <td>1.991564e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>statistician</td>\n",
       "      <td>work</td>\n",
       "      <td>math</td>\n",
       "      <td>math</td>\n",
       "      <td>3.983013e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>bailiff</td>\n",
       "      <td>work</td>\n",
       "      <td>law</td>\n",
       "      <td>law</td>\n",
       "      <td>9.807435e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>lawyer</td>\n",
       "      <td>work</td>\n",
       "      <td>law</td>\n",
       "      <td>law</td>\n",
       "      <td>2.045239e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>historian</td>\n",
       "      <td>work</td>\n",
       "      <td>history</td>\n",
       "      <td>history</td>\n",
       "      <td>1.062402e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>archivist</td>\n",
       "      <td>work</td>\n",
       "      <td>history</td>\n",
       "      <td>history</td>\n",
       "      <td>3.925437e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>historical researcher</td>\n",
       "      <td>work</td>\n",
       "      <td>history</td>\n",
       "      <td>history</td>\n",
       "      <td>5.191555e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>archaeologist</td>\n",
       "      <td>work</td>\n",
       "      <td>history</td>\n",
       "      <td>history</td>\n",
       "      <td>8.446297e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>electronics technician</td>\n",
       "      <td>work</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>7.011236e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>work</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>1.431244e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>electrical engineer</td>\n",
       "      <td>work</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>1.304718e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>software engineer</td>\n",
       "      <td>work</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>1.363839e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>web developer</td>\n",
       "      <td>work</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>3.648814e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>economic researcher</td>\n",
       "      <td>work</td>\n",
       "      <td>econ</td>\n",
       "      <td>econ</td>\n",
       "      <td>1.304612e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>economist</td>\n",
       "      <td>work</td>\n",
       "      <td>econ</td>\n",
       "      <td>econ</td>\n",
       "      <td>2.738544e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>financial analyst</td>\n",
       "      <td>work</td>\n",
       "      <td>econ</td>\n",
       "      <td>econ</td>\n",
       "      <td>6.151316e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>enthusiast</td>\n",
       "      <td>work</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>9.079468e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>partisan</td>\n",
       "      <td>work</td>\n",
       "      <td>politics</td>\n",
       "      <td>politics</td>\n",
       "      <td>4.140323e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Embedded Systems AI Engineer</td>\n",
       "      <td>AI</td>\n",
       "      <td>eecs</td>\n",
       "      <td>eecs</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             role role cate  occupation cate      merged_cate  \\\n",
       "2                    psychologist      work       psychology       psychology   \n",
       "6                      politician      work         politics         politics   \n",
       "7                         sheriff      work         politics         politics   \n",
       "9                        governer      work         politics         politics   \n",
       "10                     geneticist      work  natural science  natural science   \n",
       "19                      biologist      work  natural science  natural science   \n",
       "20                      physicist      work  natural science  natural science   \n",
       "21                        teacher    school  natural science  natural science   \n",
       "22                        chemist      work  natural science  natural science   \n",
       "26                      ecologist      work  natural science  natural science   \n",
       "28                          nurse      work         medicine         medicine   \n",
       "29                         doctor      work         medicine         medicine   \n",
       "30                      physician      work         medicine         medicine   \n",
       "33                        dentist      work         medicine         medicine   \n",
       "34                        surgeon      work         medicine         medicine   \n",
       "35                   data analyst      work             math             math   \n",
       "37                  mathematician      work             math             math   \n",
       "41                   statistician      work             math             math   \n",
       "47                        bailiff      work              law              law   \n",
       "48                         lawyer      work              law              law   \n",
       "49                      historian      work          history          history   \n",
       "50                      archivist      work          history          history   \n",
       "51          historical researcher      work          history          history   \n",
       "57                  archaeologist      work          history          history   \n",
       "58         electronics technician      work             eecs             eecs   \n",
       "60                 data scientist      work             eecs             eecs   \n",
       "62            electrical engineer      work             eecs             eecs   \n",
       "68              software engineer      work             eecs             eecs   \n",
       "80                  web developer      work             eecs             eecs   \n",
       "81            economic researcher      work             econ             econ   \n",
       "82                      economist      work             econ             econ   \n",
       "84              financial analyst      work             econ             econ   \n",
       "102                    enthusiast      work         politics         politics   \n",
       "104                      partisan      work         politics         politics   \n",
       "152  Embedded Systems AI Engineer        AI             eecs             eecs   \n",
       "\n",
       "     N-gram Frequency (2018-2019)  mmlu  interpersonal   gender align_words  \\\n",
       "2                    4.646573e-06     1              0  unknown         NaN   \n",
       "6                    5.218259e-06     1              0  unknown         NaN   \n",
       "7                    7.653504e-06     1              0  unknown         NaN   \n",
       "9                    3.078719e-09     1              0  unknown         NaN   \n",
       "10                   2.580220e-07     1              0  unknown         NaN   \n",
       "19                   1.110472e-06     1              0  unknown         NaN   \n",
       "20                   2.030176e-06     1              0  unknown         NaN   \n",
       "21                   5.522994e-05     1              0  unknown         NaN   \n",
       "22                   1.986987e-06     1              0  unknown         NaN   \n",
       "26                   2.505230e-07     1              0  unknown         NaN   \n",
       "28                   2.494348e-05     1              0  unknown         NaN   \n",
       "29                   5.117561e-05     1              0  unknown         NaN   \n",
       "30                   1.669908e-05     1              0  unknown         NaN   \n",
       "33                   2.256031e-06     1              0  unknown         NaN   \n",
       "34                   9.010343e-06     1              0  unknown         NaN   \n",
       "35                   6.469216e-08     1              0  unknown         NaN   \n",
       "37                   1.991564e-06     1              0  unknown         NaN   \n",
       "41                   3.983013e-07     1              0  unknown         NaN   \n",
       "47                   9.807435e-07     1              0  unknown         NaN   \n",
       "48                   2.045239e-05     1              0  unknown         NaN   \n",
       "49                   1.062402e-05     1              0  unknown         NaN   \n",
       "50                   3.925437e-07     1              0  unknown         NaN   \n",
       "51                   5.191555e-09     1              0  unknown         NaN   \n",
       "57                   8.446297e-07     1              0  unknown         NaN   \n",
       "58                   7.011236e-09     1              0  unknown         NaN   \n",
       "60                   1.431244e-07     1              0  unknown         NaN   \n",
       "62                   1.304718e-07     1              0  unknown         NaN   \n",
       "68                   1.363839e-07     1              0  unknown         NaN   \n",
       "80                   3.648814e-08     1              0  unknown         NaN   \n",
       "81                   1.304612e-09     1              0  unknown         NaN   \n",
       "82                   2.738544e-06     1              0  unknown         NaN   \n",
       "84                   6.151316e-08     1              0  unknown         NaN   \n",
       "102                  9.079468e-07     1              0  unknown         NaN   \n",
       "104                  4.140323e-06     1              0  unknown         NaN   \n",
       "152                  0.000000e+00     1              0  unknown         NaN   \n",
       "\n",
       "    gender_role_cate  \n",
       "2                NaN  \n",
       "6                NaN  \n",
       "7                NaN  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "19               NaN  \n",
       "20               NaN  \n",
       "21               NaN  \n",
       "22               NaN  \n",
       "26               NaN  \n",
       "28               NaN  \n",
       "29               NaN  \n",
       "30               NaN  \n",
       "33               NaN  \n",
       "34               NaN  \n",
       "35               NaN  \n",
       "37               NaN  \n",
       "41               NaN  \n",
       "47               NaN  \n",
       "48               NaN  \n",
       "49               NaN  \n",
       "50               NaN  \n",
       "51               NaN  \n",
       "57               NaN  \n",
       "58               NaN  \n",
       "60               NaN  \n",
       "62               NaN  \n",
       "68               NaN  \n",
       "80               NaN  \n",
       "81               NaN  \n",
       "82               NaN  \n",
       "84               NaN  \n",
       "102              NaN  \n",
       "104              NaN  \n",
       "152              NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from generator import Generator\n",
    "current_dir = os.path.abspath(\"\")\n",
    "processed_data_dir = os.path.join(current_dir, 'processed')\n",
    "splits_data_dir = os.path.join(current_dir, 'splits')\n",
    "\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# # Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.CRITICAL,  # Set the default logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('personas.log'),  # Log to a file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the API key and the model repository\n",
    "OPENROUTER_KEY = os.environ.get('OPENROUTER_KEY')\n",
    "repository = 'anthropic/claude-3.5-sonnet'\n",
    "model = repository.split('/')[1]\n",
    "providers = ['Anthropic']\n",
    "generator = Generator(repository, OPENROUTER_KEY, providers=providers,)\n",
    "\n",
    "# Download role info data from GitHub\n",
    "url = 'https://raw.githubusercontent.com/Jiaxin-Pei/Prompting-with-Social-Roles/refs/heads/main/data/role_info.csv'\n",
    "roles_info = pd.read_csv(url)\n",
    "\n",
    "# We are interested only in the roles that are present in mmlu\n",
    "roles_info = roles_info[roles_info['mmlu'] == 1]\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/tencent-ailab/persona-hub/refs/heads/main/data/persona.jsonl'\n",
    "personas = pd.read_json(url, lines=True)\n",
    "\n",
    "roles_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts per individual role:\n",
      "              Split                    Role  Count\n",
      "0              econ     economic researcher      3\n",
      "1              econ               economist    474\n",
      "2              econ       financial analyst    198\n",
      "3              eecs  electronics technician      3\n",
      "4              eecs          data scientist    876\n",
      "5              eecs     electrical engineer    198\n",
      "6              eecs       software engineer   2043\n",
      "7              eecs           web developer    430\n",
      "8           history               historian   3372\n",
      "9           history               archivist    125\n",
      "10          history   historical researcher     31\n",
      "11          history           archaeologist    380\n",
      "12              law                 bailiff      1\n",
      "13              law                  lawyer   1186\n",
      "14             math            data analyst    614\n",
      "15             math           mathematician    353\n",
      "16             math            statistician    228\n",
      "17         medicine                   nurse   1206\n",
      "18         medicine                  doctor   1094\n",
      "19         medicine               physician    279\n",
      "20         medicine                 dentist    101\n",
      "21         medicine                 surgeon    306\n",
      "22  natural science              geneticist    209\n",
      "23  natural science               biologist    796\n",
      "24  natural science               physicist    790\n",
      "25  natural science                 teacher   3484\n",
      "26  natural science                 chemist    690\n",
      "27  natural science               ecologist    136\n",
      "28         politics              politician   1271\n",
      "29         politics                 sheriff     25\n",
      "30         politics              enthusiast   6948\n",
      "31         politics                partisan     40\n",
      "32       psychology            psychologist   1197\n",
      "\n",
      "Overall (complessivo) statistics across all roles:\n",
      "       min_count  max_count  mean_count  total_count\n",
      "Count        1.0     6948.0  881.424242      29087.0\n"
     ]
    }
   ],
   "source": [
    "# Define the roles dictionary mapping split to its associated role strings\n",
    "roles_dict = {\n",
    "    \"econ\": [\"economic researcher\", \"economist\", \"financial analyst\"],\n",
    "    \"eecs\": [\"electronics technician\", \"data scientist\", \"electrical engineer\", \"software engineer\", \"web developer\"],\n",
    "    \"history\": [\"historian\", \"archivist\", \"historical researcher\", \"archaeologist\"],\n",
    "    \"law\": [\"bailiff\", \"lawyer\"],\n",
    "    \"math\": [\"data analyst\", \"mathematician\", \"statistician\"],\n",
    "    \"medicine\": [\"nurse\", \"doctor\", \"physician\", \"dentist\", \"surgeon\"],\n",
    "    \"natural science\": [\"geneticist\", \"biologist\", \"physicist\", \"teacher\", \"chemist\", \"ecologist\"],\n",
    "    \"politics\": [\"politician\", \"sheriff\", \"enthusiast\", \"partisan\"],\n",
    "    \"psychology\": [\"psychologist\"],\n",
    "}\n",
    "\n",
    "# Prepare a list to store counts for each individual role.\n",
    "# (We assume that the persona hub data has a column 'persona' containing text.)\n",
    "results = []\n",
    "for split, roles in roles_dict.items():\n",
    "    for role in roles:\n",
    "        # Use case-insensitive matching (skip NaNs with na=False)\n",
    "        mask = personas['persona'].str.lower().str.contains(role.lower(), na=False)\n",
    "        count = mask.sum()\n",
    "        results.append({\n",
    "            \"Split\": split,\n",
    "            \"Role\": role,\n",
    "            \"Count\": count\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Counts per individual role:\")\n",
    "print(results_df)\n",
    "\n",
    "# --- Overall (complessivo) statistics across all roles ---\n",
    "overall_stats = results_df[\"Count\"].agg(\n",
    "    min_count=\"min\",\n",
    "    max_count=\"max\",\n",
    "    mean_count=\"mean\",\n",
    "    total_count=\"sum\"\n",
    ")\n",
    "overall_stats_df = pd.DataFrame([overall_stats])\n",
    "print(\"\\nOverall (complessivo) statistics across all roles:\")\n",
    "print(overall_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/35 [00:00<00:02, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prompts for role: psychologist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_psychologist.csv\n",
      "Generating prompts for role: politician\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_politician.csv\n",
      "Generating prompts for role: sheriff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 4/35 [00:00<00:02, 13.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_sheriff.csv\n",
      "Generating prompts for role: governer\n",
      "No personas found for role: governer\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_governer_no_persona.csv\n",
      "Generating prompts for role: geneticist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_geneticist.csv\n",
      "Generating prompts for role: biologist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 8/35 [00:00<00:01, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_biologist.csv\n",
      "Generating prompts for role: physicist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_physicist.csv\n",
      "Generating prompts for role: teacher\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_teacher.csv\n",
      "Generating prompts for role: chemist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 10/35 [00:00<00:01, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_chemist.csv\n",
      "Generating prompts for role: ecologist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_ecologist.csv\n",
      "Generating prompts for role: nurse\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_nurse.csv\n",
      "Generating prompts for role: doctor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 14/35 [00:01<00:01, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_doctor.csv\n",
      "Generating prompts for role: physician\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_physician.csv\n",
      "Generating prompts for role: dentist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_dentist.csv\n",
      "Generating prompts for role: surgeon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 16/35 [00:01<00:01, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_surgeon.csv\n",
      "Generating prompts for role: data analyst\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_data analyst.csv\n",
      "Generating prompts for role: mathematician\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_mathematician.csv\n",
      "Generating prompts for role: statistician\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 20/35 [00:01<00:01, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_statistician.csv\n",
      "Generating prompts for role: bailiff\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_bailiff.csv\n",
      "Generating prompts for role: lawyer\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_lawyer.csv\n",
      "Generating prompts for role: historian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 22/35 [00:01<00:00, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_historian.csv\n",
      "Generating prompts for role: archivist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_archivist.csv\n",
      "Generating prompts for role: historical researcher\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_historical researcher.csv\n",
      "Generating prompts for role: archaeologist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 26/35 [00:01<00:00, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_archaeologist.csv\n",
      "Generating prompts for role: electronics technician\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_electronics technician.csv\n",
      "Generating prompts for role: data scientist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_data scientist.csv\n",
      "Generating prompts for role: electrical engineer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 28/35 [00:02<00:00, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_electrical engineer.csv\n",
      "Generating prompts for role: software engineer\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_software engineer.csv\n",
      "Generating prompts for role: web developer\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_web developer.csv\n",
      "Generating prompts for role: economic researcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 32/35 [00:02<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_economic researcher.csv\n",
      "Generating prompts for role: economist\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_economist.csv\n",
      "Generating prompts for role: financial analyst\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_financial analyst.csv\n",
      "Generating prompts for role: enthusiast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:02<00:00, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_enthusiast.csv\n",
      "Generating prompts for role: partisan\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_partisan.csv\n",
      "Generating prompts for role: Embedded Systems AI Engineer\n",
      "No personas found for role: Embedded Systems AI Engineer\n",
      "Prompts file already exists: raw/prompts_target_claude-3.5-sonnet_Embedded Systems AI Engineer_no_persona.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "import random\n",
    "\n",
    "task_types = [\n",
    "    \"describe\", \n",
    "    \"explain\",\n",
    "    \"design\",\n",
    "    \"what is\",\n",
    "    \"how to\",\n",
    "    \"analyze\",\n",
    "    \"compare\",\n",
    "    \"create\",\n",
    "    \"solve\",\n",
    "    \"recommend\"\n",
    "]\n",
    "\n",
    "async def generate_prompt_async(persona, i):\n",
    "    \"\"\"\n",
    "    Asynchronously generate a single prompt for a given persona.\n",
    "    \"\"\"\n",
    "    task_type = random.choice(task_types)\n",
    "    \n",
    "    instruction = f'''Generate a {task_type} prompt that this persona would likely ask:\n",
    "\n",
    "    Persona: {persona}\n",
    "\n",
    "    Rules:\n",
    "    1. The prompt should start with \"{task_type}\"\n",
    "    2. Keep it specific and under 15 words\n",
    "    3. Make it relevant to the persona's background/interests\n",
    "    4. Your output must start with \"User prompt:\"\n",
    "\n",
    "    Examples based on task types:\n",
    "    - describe: \"Describe the key features of a successful marketing campaign\"\n",
    "    - explain: \"Explain the process of setting up a home network\"\n",
    "    - design: \"Design a logo for a sustainable fashion brand\"\n",
    "    - what is: \"What is the difference between UI and UX design?\"\n",
    "    - how to: \"How to optimize a website for mobile devices?\"\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        raw_prompt = await generator.generate(instruction)\n",
    "        if 'User prompt:' in raw_prompt:\n",
    "            prompt = raw_prompt.split('User prompt:')[1].strip()\n",
    "        else:\n",
    "            prompt = raw_prompt.strip()\n",
    "        return (persona, prompt, task_type)  # Now also returning task_type\n",
    "    except Exception as e:\n",
    "        print(f'Error processing prompt {i}: {str(e)}')\n",
    "        return (persona, '', task_type)\n",
    "\n",
    "\n",
    "\n",
    "async def generate_prompts_async(personas_list, n=228):\n",
    "    \"\"\"\n",
    "    Asynchronously generate n prompts, each with a random persona.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for i in range(n):\n",
    "        # Randomly select a persona for each prompt\n",
    "        random_persona = random.choice(personas_list)\n",
    "        tasks.append(generate_prompt_async(random_persona, i))\n",
    "    \n",
    "    results = []\n",
    "    pbar = tqdm(total=n, desc=f'Generating prompts', leave=True)\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        try:\n",
    "            result = await task\n",
    "            results.append(result)\n",
    "            pbar.update(1)\n",
    "        except Exception as e:\n",
    "            print(f'Error in task: {str(e)}')\n",
    "            results.append(('ERROR', ''))  # Append empty result in case of error\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "async def main():\n",
    "\n",
    "    # Loop through the roles and generate prompts for each role\n",
    "    # implement a loading to show the progress on roles\n",
    "    for role in tqdm(roles_info['role']):\n",
    "        print(f'Generating prompts for role: {role}')\n",
    "        # Setting the paths\n",
    "        prompts_file = f'raw/prompts_target_{model}_{role}.csv'\n",
    "\n",
    "        # Get the personas for the current role by filtering the personas DataFrame\n",
    "        # if a persona['persona'] string contains the role string\n",
    "\n",
    "        personas_list = personas[personas['persona'].str.contains(role)]['persona'].tolist()\n",
    "\n",
    "        if len(personas_list) == 0:\n",
    "            print(f'No personas found for role: {role}')\n",
    "            personas_list = [role]\n",
    "            prompts_file = f'raw/prompts_target_{model}_{role}_no_persona.csv'\n",
    "\n",
    "        # If file exists, skip generating prompts\n",
    "        if os.path.exists(prompts_file):\n",
    "            print(f'Prompts file already exists: {prompts_file}')\n",
    "            continue\n",
    "    \n",
    "        print(f'Generating {128} prompts with random personas')\n",
    "        results = await generate_prompts_async(personas_list, 128)\n",
    "        \n",
    "        # Update the DataFrame creation in main():\n",
    "        df = pd.DataFrame(results, columns=['persona', 'prompt', 'task_type'])\n",
    "        \n",
    "        # Save the results to a CSV file\n",
    "        df.to_csv(prompts_file, index=False)\n",
    "\n",
    "# Get the current event loop and run the async code\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_json(data, file_path):\n",
    "    dir = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def download_generated_prompts(prompts_file, role):\n",
    "    # Load the prompts\n",
    "    prompts = pd.read_csv(prompts_file)\n",
    "    # convert filename into a json name\n",
    "    filename = os.path.basename(prompts_file)\n",
    "    filename = filename.replace('.csv', '.json')\n",
    "\n",
    "    processed_file_path = os.path.join(processed_data_dir, filename)\n",
    "    \n",
    "    instructions = prompts['prompt'].tolist()\n",
    "    # strip and remove \" from the instructions\n",
    "    instructions = [instruction.replace('\"', '').replace('*', '') for instruction in instructions]\n",
    "    dataset_json = [{'instruction': instruction.strip(), 'category': role} for instruction in instructions]\n",
    "    dump_json(dataset_json, processed_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 617.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing role governer: [Errno 2] No such file or directory: 'raw/prompts_target_claude-3.5-sonnet_governer.csv'\n",
      "Error processing role Embedded Systems AI Engineer: [Errno 2] No such file or directory: 'raw/prompts_target_claude-3.5-sonnet_Embedded Systems AI Engineer.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for role in tqdm(roles_info['role']):\n",
    "    try:\n",
    "        prompts_file = f'raw/prompts_target_{model}_{role}.csv'\n",
    "        download_generated_prompts(prompts_file, role)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing role {role}: {str(e)}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Standard Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_file(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    dir = os.path.dirname(file_path)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_alpaca():\n",
    "    processed_file_path = os.path.join(processed_data_dir, 'alpaca.json')\n",
    "\n",
    "    dataset = pd.read_csv('raw/alpaca.csv')\n",
    "\n",
    "    # filter for instructions that have empty inputs\n",
    "    mask = dataset['input'].isna() | (dataset['input'].str.strip() == '')\n",
    "    instructions = dataset.loc[mask, 'instruction'].tolist()\n",
    "\n",
    "    dataset_json = [{'instruction': instruction.strip(), 'category': None} for instruction in instructions]\n",
    "    dump_json(dataset_json, processed_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_alpaca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_base_dataset_splits():\n",
    "    base_train_path = os.path.join(splits_data_dir, 'base_train.json')\n",
    "    base_val_path = os.path.join(splits_data_dir, 'base_val.json')\n",
    "    base_test_path = os.path.join(splits_data_dir, 'base_test.json')\n",
    "\n",
    "    train_p, val_p, test_p = 0.6, 0.20, 0.20\n",
    "\n",
    "    base_instructions = []\n",
    "    for file in ['alpaca.json']:\n",
    "        with open(os.path.join(processed_data_dir, file), 'r') as f:\n",
    "            base_instructions.extend(json.load(f))\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(base_instructions)\n",
    "\n",
    "    total_size = len(base_instructions)\n",
    "    train_size = int(train_p * total_size)\n",
    "    val_size = int(val_p * total_size)\n",
    "\n",
    "    base_train_instructions = base_instructions[:train_size]\n",
    "    base_val_instructions = base_instructions[train_size:train_size+val_size]\n",
    "    base_test_instructions = base_instructions[train_size+val_size:]\n",
    "\n",
    "    dump_json(base_train_instructions, base_train_path)\n",
    "    dump_json(base_val_instructions, base_val_path)\n",
    "    dump_json(base_test_instructions, base_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_target_dataset_splits(model):\n",
    "\n",
    "    # Setting the paths\n",
    "    \n",
    "\n",
    "    #getting all the files that contain model string\n",
    "    files = [f for f in os.listdir(processed_data_dir) if model in f]\n",
    "\n",
    "    for file in files:\n",
    "        print(f'Generating splits for {file}')\n",
    "        # select target role from file name\n",
    "        #prompts_target_claude-3.5-sonnet_statistician.csv\n",
    "        target_role = file.split('_')[-1].replace('.csv', '')\n",
    "        target_train_path = os.path.join(splits_data_dir, f'target_train_{target_role}.json')\n",
    "\n",
    "        train_p  = 1\n",
    "\n",
    "        target_instructions = []\n",
    "        \n",
    "        with open(os.path.join(processed_data_dir, file), 'r') as f:\n",
    "            target_instructions.extend(json.load(f))\n",
    "\n",
    "        random.seed(42)\n",
    "        random.shuffle(target_instructions)\n",
    "\n",
    "        total_size = len(target_instructions)\n",
    "        train_size = int(train_p * total_size)\n",
    "\n",
    "        target_train_instructions = target_instructions[:train_size]\n",
    "\n",
    "        dump_json(target_train_instructions, target_train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating splits for prompts_target_claude-3.5-sonnet_psychologist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_politician.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_sheriff.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_geneticist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_biologist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_physicist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_teacher.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_chemist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_ecologist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_nurse.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_doctor.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_physician.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_dentist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_surgeon.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_data analyst.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_mathematician.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_statistician.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_bailiff.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_lawyer.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_historian.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_archivist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_historical researcher.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_archaeologist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_electronics technician.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_data scientist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_electrical engineer.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_software engineer.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_web developer.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_economic researcher.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_economist.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_financial analyst.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_enthusiast.json\n",
      "Generating splits for prompts_target_claude-3.5-sonnet_partisan.json\n"
     ]
    }
   ],
   "source": [
    "construct_base_dataset_splits()\n",
    "construct_target_dataset_splits(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(mmlu_data):\n",
    "    processed_data = []\n",
    "    \n",
    "    # Letter mapping for answers (0->A, 1->B, 2->C, 3->D)\n",
    "    letter_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    letter_mapping_answer = {1: 'A', 2: 'B', 3: 'C', 4: 'D'}\n",
    "    \n",
    "    for item in mmlu_data:\n",
    "        question = item['question']\n",
    "        answer = item['true_option']\n",
    "        choices = [item['option1'], item['option2'], item['option3'], item['option4']]\n",
    "        subject = item['subject']\n",
    "        \n",
    "        # Create the formatted choices string\n",
    "        formatted_choices = ''\n",
    "        for i, choice in enumerate(choices):\n",
    "            formatted_choices += f\"\\n\\t\\t\\t{letter_mapping[i]}. {choice}\"\n",
    "        \n",
    "        # Create the instruction string\n",
    "        instruction = (f\"{question}{formatted_choices}\\n\\t\\t\\t\"\n",
    "                      f\"Answer with the letter of the correct answer.\\n\\t\\t\\t\"\n",
    "                      f\"Answer:\")\n",
    "        \n",
    "        # Convert numeric answer to letter\n",
    "        target_score = letter_mapping_answer[answer]\n",
    "        \n",
    "        new_item = {\n",
    "            \"instruction\": instruction,\n",
    "            \"target_score\": target_score,\n",
    "            \"dataset\": subject,\n",
    "        }\n",
    "        processed_data.append(new_item)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "def processing_mmlu_data(file):\n",
    "    mmlu_path = os.path.join(processed_data_dir, file)\n",
    "    mmlu_processed_path = os.path.join(splits_data_dir, file)\n",
    "\n",
    "    try:\n",
    "        with open(mmlu_path, 'r') as f:\n",
    "            mmlu = json.load(f)\n",
    "            \n",
    "        mmlu_processed = convert_format(mmlu)\n",
    "        print(f\"Processed {len(mmlu_processed)} MMLU examples\")\n",
    "        dump_json(mmlu_processed, mmlu_processed_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 590 MMLU examples\n",
      "Processed 492 MMLU examples\n",
      "Processed 247 MMLU examples\n",
      "Processed 200 MMLU examples\n",
      "Processed 287 MMLU examples\n",
      "Processed 241 MMLU examples\n",
      "Processed 200 MMLU examples\n",
      "Processed 200 MMLU examples\n"
     ]
    }
   ],
   "source": [
    "processing_mmlu_data(\"target_test_natural_science.json\")\n",
    "processing_mmlu_data(\"target_test_econ.json\")\n",
    "processing_mmlu_data(\"target_test_eecs.json\")\n",
    "processing_mmlu_data(\"target_test_law.json\")\n",
    "processing_mmlu_data(\"target_test_math.json\")\n",
    "processing_mmlu_data(\"target_test_medicine.json\")\n",
    "processing_mmlu_data(\"target_test_politics.json\")\n",
    "processing_mmlu_data(\"target_test_psychology.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
