{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Reversed Analysis Prompt**\n",
    "\n",
    "I want to build a table to present an analysis about roles in models, with models as rows and roles as columns. Do it in python code\n",
    "\n",
    "**Directory Structure Overview:**\n",
    "\n",
    "- There is a main directory with subdirectories for each model.\n",
    "- Within each model directory, there are subdirectories for each role.\n",
    "- Inside every role directory, you will find eight (split) subdirectories. (At this level, ignore both the `generate_directions` and the `select_direction` directories if they appear outside the designated paths.)\n",
    "- Use the following mapping to associate splits with roles:\n",
    "\n",
    "```python\n",
    "ROLE_DATASET_MAPPING = {\n",
    "    \"econ\": [\"economic researcher\", \"economist\", \"financial analyst\"],\n",
    "    \"eecs\": [\"electronics technician\", \"data scientist\", \"electrical engineer\", \"software engineer\", \"web developer\"],\n",
    "    \"law\": [\"bailiff\", \"lawyer\"],\n",
    "    \"math\": [\"data analyst\", \"mathematician\", \"statistician\"],\n",
    "    \"medicine\": [\"nurse\", \"doctor\", \"physician\", \"dentist\", \"surgeon\"],\n",
    "    \"natural_science\": [\"geneticist\", \"biologist\", \"physicist\", \"teacher\", \"chemist\", \"ecologist\"],\n",
    "    \"politics\": [\"politician\", \"sheriff\", \"governor\", \"enthusiast\", \"partisan\"],\n",
    "    \"psychology\": [\"psychologist\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Analysis Steps (Reversed Order):**\n",
    "\n",
    "1. **Identify Passed Directions from Test Results:**\n",
    "\n",
    "   - For each model and role, navigate to the test directions at version 3.0:\n",
    "     \n",
    "     ```\n",
    "     {models}\\{model}\\{role}\\test_direction\\3.0\n",
    "     ```\n",
    "     \n",
    "   - In this directory, you will find multiple JSON files, each corresponding to a direction (named as `{layer}_{position}.json`).\n",
    "   - Open each file and examine the JSON array. For every direction object, check if the `\"passed\"` field is `\"Yes\"`.\n",
    "   - Collect all unique `(layer, position)` pairs from these files that have `\"passed\": \"Yes\"`. This constitutes your *passed directions set*.\n",
    "\n",
    "2. **Retrieve Directions from Role’s Split Data:**\n",
    "\n",
    "   - Now, for the same model/role, explore the split directories associated with that role.\n",
    "   - For each applicable split (ignoring any unrelated ones), go into the following paths to retrieve the directions:\n",
    "     \n",
    "     - **First Source:**  \n",
    "       ```\n",
    "       {models}\\{model}\\{role}\\{split}\\1.0\\select_direction\\direction_evaluations_filtered.json\n",
    "       ```\n",
    "     \n",
    "     - **Second Source:**  \n",
    "       ```\n",
    "       {models}\\{model}\\{role}\\{split}\\3.0\\select_direction\\direction_evaluations_filtered.json\n",
    "       ```\n",
    "     \n",
    "   - From each `direction_evaluations_filtered.json` file, extract the set of unique `(layer, position)` pairs.\n",
    "\n",
    "3. **Compare and Calculate the Percentage:**\n",
    "\n",
    "   - For each model/role, determine how many directions from your *passed directions set* (from Step 1) are present in the union of the `(layer, position)` pairs from the select_direction files (from Step 2).\n",
    "   - Calculate the percentage using the formula:\n",
    "     \n",
    "     \\[\n",
    "     \\text{Percentage} = \\frac{\\text{Number of Passed Directions Found in Select\\_Direction Files}}{\\text{Total Number of Passed Directions}} \\times 100\n",
    "     \\]\n",
    "     \n",
    "4. **Populate the Table:**\n",
    "\n",
    "   - Create a table where the rows represent models and the columns represent roles.\n",
    "   - In each cell (model/role), report the computed percentage from Step 3.\n",
    "\n",
    "This reversed approach starts with collecting the directions that successfully passed the test and then checks for their presence in the role’s split (select_direction) data. The final table will show, for each model and role, what percentage of the passed directions are accounted for in the split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Mapping from splits to associated roles (note: \"governor\" has been removed)\n",
    "ROLE_DATASET_MAPPING = {\n",
    "    \"econ\": [\"economic researcher\", \"economist\", \"financial analyst\"],\n",
    "    \"eecs\": [\"electronics technician\", \"data scientist\", \"electrical engineer\", \"software engineer\", \"web developer\"],\n",
    "    \"law\": [\"bailiff\", \"lawyer\"],\n",
    "    \"math\": [\"data analyst\", \"mathematician\", \"statistician\"],\n",
    "    \"medicine\": [\"nurse\", \"doctor\", \"physician\", \"dentist\", \"surgeon\"],\n",
    "    \"natural_science\": [\"geneticist\", \"biologist\", \"physicist\", \"teacher\", \"chemist\", \"ecologist\"],\n",
    "    \"politics\": [\"politician\", \"sheriff\", \"enthusiast\", \"partisan\"],\n",
    "    \"psychology\": [\"psychologist\"]\n",
    "}\n",
    "\n",
    "def debug_print(message):\n",
    "    \"\"\"Simple debug print function.\"\"\"\n",
    "    print(f\"DEBUG: {message}\")\n",
    "\n",
    "def evaluate_direction(role_dir, direction):\n",
    "    \"\"\"\n",
    "    Given a role directory and a (layer, position) tuple, check the test result.\n",
    "    The test file is expected at:\n",
    "       {role_dir}/test_direction/3.0/{layer}_{position}.json\n",
    "    Returns True if any entry in that file has \"passed\" == \"Yes\" (case insensitive),\n",
    "    otherwise returns False.\n",
    "    \"\"\"\n",
    "    layer, position = direction\n",
    "    filename = f\"{layer}_{position}.json\"\n",
    "    test_file = os.path.join(role_dir, \"test_direction\", \"3.0\", filename)\n",
    "    debug_print(f\"Evaluating direction {direction} using test file: {test_file}\")\n",
    "    \n",
    "    if not os.path.isfile(test_file):\n",
    "        debug_print(f\"Test file not found: {test_file}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        with open(test_file, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "            for res in results:\n",
    "                passed_val = str(res.get(\"passed\", \"\")).strip().lower()\n",
    "                debug_print(f\"In file {test_file}, found passed value: '{passed_val}'\")\n",
    "                if passed_val == \"yes\":\n",
    "                    return True\n",
    "    except Exception as e:\n",
    "        debug_print(f\"Error reading {test_file}: {e}\")\n",
    "    return False\n",
    "\n",
    "def get_split_for_role(role_name):\n",
    "    \"\"\"\n",
    "    Given a role name, return the corresponding split key from ROLE_DATASET_MAPPING.\n",
    "    \"\"\"\n",
    "    for split, roles in ROLE_DATASET_MAPPING.items():\n",
    "        if role_name in roles:\n",
    "            return split\n",
    "    debug_print(f\"No split mapping found for role '{role_name}'.\")\n",
    "    return None\n",
    "\n",
    "def get_passed_directions(model_path, role):\n",
    "    \"\"\"\n",
    "    For a given model and role, use evaluate_direction to check each test file in:\n",
    "       {model_path}/{role}/test_direction/3.0\n",
    "    Each file is named {layer}_{position}.json. Convert these values to integers and,\n",
    "    if evaluate_direction returns True, add the (layer, position) tuple to the set.\n",
    "    Returns a set of unique (layer, position) tuples that passed.\n",
    "    \"\"\"\n",
    "    passed_directions = set()\n",
    "    role_dir = os.path.join(model_path, role)\n",
    "    test_dir = os.path.join(role_dir, \"test_direction\", \"3.0\")\n",
    "    if not os.path.isdir(test_dir):\n",
    "        debug_print(f\"Test direction directory does not exist: {test_dir}\")\n",
    "        return passed_directions  # Return empty set if the directory does not exist\n",
    "\n",
    "    json_files = glob.glob(os.path.join(test_dir, \"*.json\"))\n",
    "    if not json_files:\n",
    "        debug_print(f\"No JSON files found in test direction directory: {test_dir}\")\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        base = os.path.basename(json_file)\n",
    "        if not base.endswith(\".json\"):\n",
    "            continue\n",
    "        # Remove the '.json' extension and split into layer and position.\n",
    "        name = base[:-5]\n",
    "        parts = name.split(\"_\")\n",
    "        if len(parts) != 2:\n",
    "            debug_print(f\"Filename {base} does not match expected format 'layer_position.json'\")\n",
    "            continue\n",
    "        try:\n",
    "            # Convert layer and position to integers\n",
    "            layer = int(parts[0])\n",
    "            position = int(parts[1])\n",
    "        except Exception as e:\n",
    "            debug_print(f\"Error converting {parts} to int: {e}\")\n",
    "            continue\n",
    "        direction = (layer, position)\n",
    "        if evaluate_direction(role_dir, direction):\n",
    "            passed_directions.add(direction)\n",
    "    debug_print(f\"For model '{os.path.basename(model_path)}', role '{role}', found {len(passed_directions)} passed directions.\")\n",
    "    return passed_directions\n",
    "\n",
    "def get_select_directions(model_path, role, split):\n",
    "    \"\"\"\n",
    "    For a given model, role, and the applicable split, retrieve the union of directions\n",
    "    from both versions of the select_direction file:\n",
    "       {model_path}/{role}/{split}/1.0/select_direction/direction_evaluations_filtered.json\n",
    "       {model_path}/{role}/{split}/3.0/select_direction/direction_evaluations_filtered.json\n",
    "    Returns a set of unique (layer, position) tuples.\n",
    "    \"\"\"\n",
    "    select_directions = set()\n",
    "    for version in [\"1.0\", \"3.0\"]:\n",
    "        file_path = os.path.join(model_path, role, split, version, \"select_direction\", \"direction_evaluations_filtered.json\")\n",
    "        if not os.path.isfile(file_path):\n",
    "            debug_print(f\"File does not exist: {file_path}\")\n",
    "            continue\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                directions = json.load(f)\n",
    "            for direction in directions:\n",
    "                layer = direction.get(\"layer\")\n",
    "                position = direction.get(\"position\")\n",
    "                if layer is not None and position is not None:\n",
    "                    try:\n",
    "                        layer = int(layer)\n",
    "                        position = int(position)\n",
    "                    except Exception as e:\n",
    "                        debug_print(f\"Error converting select_direction values {layer}, {position} to int: {e}\")\n",
    "                        continue\n",
    "                    select_directions.add((layer, position))\n",
    "        except Exception as e:\n",
    "            debug_print(f\"Error processing {file_path}: {e}\")\n",
    "    debug_print(f\"For model '{os.path.basename(model_path)}', role '{role}', split '{split}', found {len(select_directions)} select directions.\")\n",
    "    return select_directions\n",
    "\n",
    "def compute_percentage(passed_set, select_set):\n",
    "    \"\"\"\n",
    "    Given the passed directions set and the select_direction set,\n",
    "    calculate the percentage of passed directions that are found in the select data.\n",
    "    If the passed_set is empty, returns 0.\n",
    "    \"\"\"\n",
    "    if not passed_set:\n",
    "        debug_print(\"No passed directions to compute percentage. Setting percentage to 0.\")\n",
    "        return 0  # Set percentage to 0 when no passed directions exist.\n",
    "    debug_print(f\"Passed directions: {passed_set}\")\n",
    "    debug_print(f\"Select directions: {select_set}\")\n",
    "    common = passed_set.intersection(select_set)\n",
    "    percentage = (len(common) / len(passed_set)) * 100\n",
    "    debug_print(f\"Found {len(common)} common directions out of {len(passed_set)} passed directions.\")\n",
    "    return percentage\n",
    "\n",
    "def analyze_models(base_dir):\n",
    "    \"\"\"\n",
    "    Iterates through each model and role, computes the percentage of passed directions\n",
    "    (from test results) that are found in the select_direction files.\n",
    "    Builds and returns a pandas DataFrame with roles as rows and models as columns.\n",
    "    \"\"\"\n",
    "    # List all model directories\n",
    "    models = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    if not models:\n",
    "        debug_print(f\"No models found in base directory: {base_dir}\")\n",
    "    \n",
    "    # Build a sorted list of all roles from ROLE_DATASET_MAPPING\n",
    "    roles = set()\n",
    "    for role_list in ROLE_DATASET_MAPPING.values():\n",
    "        roles.update(role_list)\n",
    "    roles = sorted(roles)\n",
    "\n",
    "    # Dictionary to hold the results: {model: {role: percentage}}\n",
    "    results = {}\n",
    "    for model in models:\n",
    "        model_path = os.path.join(base_dir, model)\n",
    "        debug_print(f\"Processing model: {model}\")\n",
    "        results[model] = {}\n",
    "        for role in roles:\n",
    "            role_dir = os.path.join(model_path, role)\n",
    "            if not os.path.isdir(role_dir):\n",
    "                debug_print(f\"Role directory does not exist for model '{model}': {role_dir}\")\n",
    "                results[model][role] = 0\n",
    "                continue\n",
    "\n",
    "            # Get passed directions using evaluate_direction\n",
    "            passed_directions = get_passed_directions(model_path, role)\n",
    "            if not passed_directions:\n",
    "                debug_print(f\"No passed directions found for model '{model}', role '{role}'.\")\n",
    "\n",
    "            # Determine the applicable split for this role using the mapping\n",
    "            split = get_split_for_role(role)\n",
    "            if not split:\n",
    "                results[model][role] = 0\n",
    "                continue\n",
    "\n",
    "            # Retrieve directions from the role's split select_direction files\n",
    "            select_directions = get_select_directions(model_path, role, split)\n",
    "            if not select_directions:\n",
    "                debug_print(f\"No select directions found for model '{model}', role '{role}', split '{split}'.\")\n",
    "\n",
    "            # Compute the percentage match\n",
    "            pct = compute_percentage(passed_directions, select_directions)\n",
    "            results[model][role] = pct\n",
    "\n",
    "    # Build DataFrame with models as rows, then transpose it so roles are rows and models are columns.\n",
    "    df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "    df = df.transpose()  # Now rows are roles and columns are models.\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the base directory containing your model subdirectories\n",
    "    base_dir = r\"C:\\Users\\user\\Desktop\\temp\\rolevectors_results\"  \n",
    "    df = analyze_models(base_dir)\n",
    "\n",
    "    # Format the percentages for display:\n",
    "    df_formatted = df.applymap(lambda x: f\"{x:.2f}%\" if isinstance(x, (int, float)) else \"N/A\")\n",
    "    \n",
    "    print(\"\\nFinal Percentage Table:\")\n",
    "    print(df_formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum across columns (axis=1) and sort\n",
    "role_totals = df.sum(axis=0).sort_values()\n",
    "\n",
    "print(role_totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum down the columns (axis=0) to get the total presence per model\n",
    "model_totals = df.sum(axis=0)\n",
    "\n",
    "# Sort these sums in ascending order\n",
    "sorted_model_totals = model_totals.sort_values()\n",
    "\n",
    "# Reorder the columns in the DataFrame to match this sorted order\n",
    "df_sorted_models = df[sorted_model_totals.index]\n",
    "\n",
    "df_sorted_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sorted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def latex_blue_gradient(val, vmin=0, vmax=100):\n",
    "    \"\"\"\n",
    "    Convert a numerical value into a LaTeX string that applies a blue background.\n",
    "    The intensity of the blue (using xcolor's syntax) is determined by the value's\n",
    "    position between vmin and vmax.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        numeric_val = float(val)\n",
    "    except Exception:\n",
    "        numeric_val = 0.0\n",
    "\n",
    "    # Normalize the value between vmin and vmax\n",
    "    norm_val = (numeric_val - vmin) / (vmax - vmin)\n",
    "    norm_val = np.clip(norm_val, 0, 1)\n",
    "\n",
    "    # Map normalized value to an intensity percentage (e.g., 0 to 50)\n",
    "    intensity = int(norm_val * 50)\n",
    "    \n",
    "    # Create the cell color command. If intensity is 0, no color command is added.\n",
    "    color_cmd = f\"\\\\cellcolor{{blue!{intensity}}}\" if intensity > 0 else \"\"\n",
    "    \n",
    "    # Return the LaTeX string with the background color and the value (formatted to 2 decimals)\n",
    "    return f\"{color_cmd} $ {numeric_val:.2f} $\"\n",
    "\n",
    "def style_df_to_latex(df, vmin=0, vmax=100):\n",
    "    \"\"\"\n",
    "    Apply the blue gradient styling to every cell in the DataFrame,\n",
    "    converting each cell to a LaTeX string that includes a background color.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame\n",
    "    df_styled = df.copy()\n",
    "    \n",
    "    # Apply our custom LaTeX styling function cell-by-cell\n",
    "    for col in df.columns:\n",
    "        df_styled[col] = df[col].apply(lambda x: latex_blue_gradient(x, vmin, vmax))\n",
    "    \n",
    "    return df_styled\n",
    "\n",
    "# --- Usage Example ---\n",
    "\n",
    "# Suppose your DataFrame is called df.\n",
    "# (You might have created it or loaded it from somewhere.)\n",
    "\n",
    "# Instead of using .style.background_gradient for HTML output,\n",
    "# we create a new DataFrame with LaTeX-formatted strings.\n",
    "df_latex_styled = style_df_to_latex(df, vmin=0, vmax=100)\n",
    "\n",
    "# Convert the styled DataFrame to LaTeX code.\n",
    "# Note: escape=False is needed so that our LaTeX commands are not escaped.\n",
    "latex_code = df_latex_styled.to_latex(escape=False)\n",
    "print(latex_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
